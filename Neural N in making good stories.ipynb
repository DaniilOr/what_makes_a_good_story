{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from ast import literal_eval\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONSTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOC_SIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lodading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open('processed_dict.txt','r')\n",
    "d=f.read()\n",
    "d= literal_eval(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemmer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer=RussianStemmer()\n",
    "regular = re.compile('[^а-яА-Я]')\n",
    "stem_cache = {}\n",
    "def get_stem(token):\n",
    "    stem=stem_cache.get(token, None)\n",
    "    if stem:\n",
    "        return stem\n",
    "    token=regular.sub('',token).lower()\n",
    "    stem=stemmer.stem(token)\n",
    "    stem_cache[token]=stem\n",
    "    return stem\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vocabulary creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique stems number: 14436\n"
     ]
    }
   ],
   "source": [
    "stem_counter=Counter()\n",
    "tokenizer=TweetTokenizer()\n",
    "def count_unique_tokens_in_stories(stories):\n",
    "    for pair in stories.items():\n",
    "        words=tokenizer.tokenize(pair[0])\n",
    "        #print(words)\n",
    "        for word in words:\n",
    "            stem=get_stem(word)\n",
    "            stem_counter[stem]+=1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "count_unique_tokens_in_stories(d)\n",
    "print('Unique stems number: '+ str(len(stem_counter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = sorted(stem_counter, key=stem_counter.get, reverse=True)[:VOC_SIZE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'и': 0, 'в': 1, 'я': 2, 'на': 3, 'не': 4, 'он': 5, 'что': 6, '': 7, 'с': 8, 'эт': 9, 'был': 10, 'а': 11, 'как': 12, 'так': 13, 'у': 14, 'мен': 15, 'мне': 16, 'к': 17, 'мо': 18, 'мы': 19, 'по': 20, 'за': 21, 'е': 22, 'но': 23, 'все': 24, 'когд': 25, 'ег': 26, 'то': 27, 'из': 28, 'ну': 29, 'вот': 30, 'сво': 31, 'друг': 32, 'нача': 33, 'пот': 34, 'от': 35, 'говор': 36, 'котор': 37, 'сказа': 38, 'позор': 39, 'ты': 40, 'ещ': 41, 'дом': 42, 'лет': 43, 'там': 44, 'тут': 45, 'уж': 46, 'реш': 47, 'нас': 48, 'сам': 49, 'же': 50, 'чтоб': 51, 'до': 52, 'ем': 53, 'посл': 54, 'со': 55, 'прост': 56, 'пошл': 57, 'одн': 58, 'блят': 59, 'раз': 60, 'дума': 61, 'итог': 62, 'этот': 63, 'нег': 64, 'теб': 65, 'тольк': 66, 'себ': 67, 'их': 68, 'бы': 69, 'бат': 70, 'рук': 71, 'мужик': 72, 'наш': 73, 'ест': 74, 'через': 75, 'сегодн': 76, 'пиздец': 77, 'один': 78, 'мам': 79, 'пришл': 80, 'говн': 81, 'тип': 82, 'нет': 83, 'вы': 84, 'ху': 85, 'истор': 86, 'сто': 87, 'стал': 88, 'есл': 89, 'год': 90, 'минут': 91, 'нам': 92, 'дел': 93, 'о': 94, 'ден': 95, 'девушк': 96, 'больш': 97, 'дела': 98, 'вс': 99, 'привет': 100, 'про': 101, 'над': 102, 'да': 103, 'еба': 104, 'дед': 105, 'под': 106, 'сдела': 107, 'школ': 108, 'врем': 109, 'сук': 110, 'нич': 111, 'очен': 112, 'где': 113, 'тог': 114, 'слов': 115, 'для': 116, 'взял': 117, 'бомж': 118, 'начина': 119, 'ве': 120, 'двер': 121, 'час': 122, 'туалет': 123, 'ответ': 124, 'даж': 125, 'дал': 126, 'ним': 127, 'смотр': 128, 'перв': 129, 'пок': 130, 'пизд': 131, 'ноч': 132, 'пол': 133, 'телефон': 134, 'кто': 135, 'короч': 136, 'хотел': 137, 'сидел': 138, 'ход': 139, 'куп': 140, 'увидел': 141, 'поня': 142, 'том': 143, 'ил': 144, 'нах': 145, 'город': 146, 'тепер': 147, 'сейчас': 148, 'знач': 149, 'ид': 150, 'стоя': 151, 'них': 152, 'подруг': 153, 'будет': 154, 'друз': 155, 'тож': 156, 'во': 157, 'стыдн': 158, 'прям': 159, 'вид': 160, 'комнат': 161, 'момент': 162, 'брат': 163, 'люд': 164, 'класс': 165, 'перед': 166, 'родител': 167, 'утр': 168, 'тот': 169, 'жоп': 170, 'вообщ': 171, 'баб': 172, 'голов': 173, 'бабушк': 174, 'вмест': 175, 'машин': 176, 'пар': 177, 'мол': 178, 'мно': 179, 'кажд': 180, 'спрос': 181, 'тво': 182, 'оказа': 183, 'назад': 184, 'ко': 185, 'без': 186, 'пост': 187, 'след': 188, 'виж': 189, 'вод': 190, 'мат': 191, 'ног': 192, 'спрашива': 193, 'приеха': 194, 'деньг': 195, 'глаз': 196, 'парн': 197, 'пошел': 198, 'может': 199, 'жизн': 200, 'окн': 201, 'сраз': 202, 'ряд': 203, 'им': 204, 'чем': 205, 'улиц': 206, 'бабк': 207, 'ли': 208, 'общ': 209, 'человек': 210, 'ора': 211, 'хот': 212, 'собак': 213, 'всю': 214, 'всем': 215, 'чтот': 216, 'зашл': 217, 'тем': 218, 'выход': 219, 'сиж': 220, 'карп': 221, 'чита': 222, 'приход': 223, 'об': 224, 'вам': 225, 'узна': 226, 'нужн': 227, 'гуля': 228, 'подума': 229, 'сид': 230, 'какт': 231, 'автобус': 232, 'тк': 233, 'работа': 234, 'хуйн': 235, 'дальш': 236, 'хорош': 237, 'оста': 238, 'туд': 239, 'получ': 240, 'мест': 241, 'понима': 242, 'буд': 243, 'п': 244, 'дорог': 245, 'сел': 246, 'однажд': 247, 'тогд': 248, 'недел': 249, 'буха': 250, 'мамк': 251, 'сильн': 252, 'рассказа': 253, 'вчер': 254, 'паца': 255, 'знает': 256, 'можн': 257, 'написа': 258, 'сестр': 259, 'изз': 260, 'игра': 261, 'встал': 262, 'лиц': 263, 'немн': 264, 'при': 265, 'магазин': 266, 'мог': 267, 'трус': 268, 'вдруг': 269, 'жив': 270, 'пыта': 271, 'пор': 272, 'долг': 273, 'нов': 274, 'обосра': 275, 'подход': 276, 'чут': 277, 'какойт': 278, 'чег': 279, 'штан': 280, 'лучш': 281, 'месяц': 282, 'еха': 283, 'деревн': 284, 'парен': 285, 'упа': 286, 'заход': 287, 'урок': 288, 'нашл': 289, 'дроч': 290, 'вечер': 291, 'рот': 292, 'ни': 293, 'недавн': 294, 'че': 295, 'два': 296, 'отец': 297, 'всех': 298, 'бух': 299, 'спал': 300, 'двор': 301, 'ушл': 302, 'обычн': 303, 'поеха': 304, 'дет': 305, 'мног': 306, 'хоч': 307, 'откр': 308, 'нем': 309, 'идт': 310, 'ед': 311, 'прошл': 312, 'всегд': 313, 'работ': 314, 'врод': 315, 'леж': 316, 'поч': 317, 'люб': 318, 'заб': 319, 'срат': 320, 'нескольк': 321, 'бол': 322, 'попрос': 323, 'лежа': 324, 'втор': 325, 'никт': 326, 'училк': 327, 'вспомн': 328, 'секс': 329, 'захотел': 330, 'бутылк': 331, 'конц': 332, 'знаком': 333, 'нормальн': 334, 'крч': 335, 'женщин': 336, 'замет': 337, 'член': 338, 'доста': 339, 'конечн': 340, 'маленьк': 341, 'больниц': 342, 'постоя': 343, 'вся': 344, 'вас': 345, 'всег': 346, 'кароч': 347, 'детств': 348, 'встреча': 349, 'помн': 350, 'бля': 351, 'полн': 352, 'спат': 353, 'сторон': 354, 'проход': 355, 'девочк': 356, 'скор': 357, 'никогд': 358, 'дня': 359, 'зна': 360, 'дава': 361, 'конч': 362, 'снима': 363, 'уч': 364, 'жен': 365, 'рубл': 366, 'ебан': 367, 'сын': 368, 'открыва': 369, 'кухн': 370, 'проснул': 371, 'занима': 372, 'быт': 373, 'ваш': 374, 'быстр': 375, 'пакет': 376, 'пацан': 377, 'денег': 378, 'хул': 379, 'последн': 380, 'стол': 381, 'вышел': 382, 'сем': 383, 'кров': 384, 'побежа': 385, 'предлож': 386, 'позорчан': 387, 'мал': 388, 'остановк': 389, 'мелк': 390, 'аху': 391, 'част': 392, 'мент': 393, 'вышл': 394, 'сосед': 395, 'девк': 396, 'слыш': 397, 'постав': 398, 'вед': 399, 'окол': 400, 'метр': 401, 'знал': 402, 'охуел': 403, 'смотрел': 404, 'душ': 405, 'картин': 406, 'подошл': 407, 'сих': 408, 'позва': 409, 'показа': 410, 'рассказыва': 411, 'ник': 412, 'стран': 413, 'цел': 414, 'полож': 415, 'обратн': 416, 'имен': 417, 'куд': 418, 'дик': 419, 'тд': 420, 'слуша': 421, 'пришел': 422, 'та': 423, 'яйц': 424, 'этаж': 425, 'пох': 426, 'телк': 427, 'возл': 428, 'видел': 429, 'опя': 430, 'вопрос': 431, 'естествен': 432, 'собира': 433, 'плох': 434, 'ахуел': 435, 'законч': 436, 'пьян': 437, 'спасиб': 438, 'алкаш': 439, 'земл': 440, 'почт': 441, 'мим': 442, 'одноклассник': 443, 'квартир': 444, 'посла': 445, 'дне': 446, 'гост': 447, 'зач': 448, 'случа': 449, 'остав': 450, 'маршрутк': 451, 'нос': 452, 'иб': 453, 'секунд': 454, 'спуст': 455, 'всяк': 456, 'съеба': 457, 'д': 458, 'поэт': 459, 'старш': 460, 'забра': 461, 'произошл': 462, 'случ': 463, 'отвеча': 464, 'кур': 465, 'закр': 466, 'чувств': 467, 'стар': 468, 'звон': 469, 'хз': 470, 'воня': 471, 'услыша': 472, 'резк': 473, 'ван': 474, 'ебуч': 475, 'пап': 476, 'мир': 477, 'разн': 478, 'нрав': 479, 'жил': 480, 'подъезд': 481, 'посра': 482, 'зат': 483, 'чист': 484, 'дач': 485, 'ел': 486, 'ктот': 487, 'зап': 488, 'показыва': 489, 'хат': 490, 'ниху': 491, 'гараж': 492, 'обща': 493, 'кида': 494, 'собра': 495, 'получа': 496, 'уеха': 497, 'вещ': 498, 'должн': 499, 'спокойн': 500, 'позвон': 501, 'гдет': 502, 'матер': 503, 'тех': 504, 'волос': 505, 'кинул': 506, 'уход': 507, 'посмотрел': 508, 'снача': 509, 'вписк': 510, 'молод': 511, 'туп': 512, 'груд': 513, 'три': 514, 'вызва': 515, 'какаят': 516, 'лес': 517, 'дерьм': 518, 'групп': 519, 'равн': 520, 'ладн': 521, 'давн': 522, 'ям': 523, 'мальчик': 524, 'свет': 525, 'страшн': 526, 'чувак': 527, 'останов': 528, 'иногд': 529, 'бега': 530, 'прос': 531, 'ебанут': 532, 'брос': 533, 'угара': 534, 'хочет': 535, 'летн': 536, 'примерн': 537, 'наблюда': 538, 'мужчин': 539, 'держ': 540, 'обосса': 541, 'наверн': 542, 'выеба': 543, 'куч': 544, 'пада': 545, 'подня': 546, 'могл': 547, 'кот': 548, 'кабинет': 549, 'диалог': 550, 'сход': 551, 'кстат': 552, 'смотрет': 553, 'русск': 554, 'плат': 555, 'приезжа': 556, 'очеред': 557, 'сут': 558, 'вып': 559, 'интересн': 560, 'моч': 561, 'снял': 562, 'удар': 563, 'шлюх': 564, 'спизд': 565, 'ебнул': 566, 'уснул': 567, 'попа': 568, 'заеба': 569, 'живот': 570, 'быва': 571, 'крыш': 572, 'норм': 573, 'захож': 574, 'случайн': 575, 'езд': 576, 'смог': 577, 'ког': 578, 'пут': 579, 'магаз': 580, 'пиш': 581, 'врач': 582, 'щас': 583, 'отц': 584, 'палк': 585, 'ор': 586, 'учител': 587, 'кроват': 588, 'ча': 589, 'покупа': 590, 'отправ': 591, 'бумаг': 592, 'орет': 593, 'бляд': 594, 'главн': 595, 'водк': 596, 'пиздюк': 597, 'встрет': 598, 'спин': 599, 'трога': 600, 'насра': 601, 'зал': 602, 'свин': 603, 'две': 604, 'мраз': 605, 'разб': 606, 'включ': 607, 'продолжа': 608, 'хер': 609, 'конец': 610, 'арм': 611, 'совс': 612, 'росс': 613, 'вернул': 614, 'раньш': 615, 'пздц': 616, 'детск': 617, 'мамаш': 618, 'зуб': 619, 'охранник': 620, 'директор': 621, 'готов': 622, 'огромн': 623, 'очк': 624, 'жирн': 625, 'пойт': 626, 'убежа': 627, 'скольк': 628, 'времен': 629, 'стен': 630, 'крич': 631, 'велик': 632, 'дат': 633, 'бел': 634, 'сад': 635, 'иска': 636, 'долж': 637, 'крик': 638, 'приня': 639, 'помога': 640, 'бывш': 641, 'жит': 642, 'банк': 643, 'потеря': 644, 'паблик': 645, 'жду': 646, 'сумк': 647, 'прав': 648, 'порнух': 649, 'долбоеб': 650, 'посмотрет': 651, 'двух': 652, 'игр': 653, 'мухосранск': 654, 'отпизд': 655, 'называ': 656, 'дяд': 657, 'отда': 658, 'происход': 659, 'охуен': 660, 'подошел': 661, 'разговарива': 662, 'голос': 663, 'наход': 664, 'любим': 665, 'никак': 666, 'хвата': 667, 'балкон': 668, 'помощ': 669, 'просыпа': 670, 'срал': 671, 'снов': 672, 'пальц': 673, 'муж': 674, 'младш': 675, 'ждал': 676, 'соб': 677, 'некотор': 678, 'рожден': 679, 'зашел': 680, 'др': 681, 'ран': 682, 'пит': 683, 'шла': 684, 'музык': 685, 'позж': 686, 'ребят': 687, 'сигарет': 688, 'пидор': 689, 'долбаеб': 690, 'ок': 691, 'рад': 692, 'сил': 693, 'напрот': 694, 'замеча': 695, 'местн': 696, 'тел': 697, 'вер': 698, 'почувствова': 699, 'оказыва': 700, 'провод': 701, 'насса': 702, 'звук': 703, 'крут': 704, 'трет': 705, 'бежа': 706, 'пуст': 707, 'соседк': 708, 'компан': 709, 'клуб': 710, 'нашел': 711, 'ту': 712, 'кол': 713, 'очередн': 714, 'красив': 715, 'будт': 716, 'даун': 717, 'выкинул': 718, 'херн': 719, 'карма': 720, 'пят': 721, 'довольн': 722, 'уеба': 723, 'мысл': 724, 'видим': 725, 'писа': 726, 'ч': 727, 'друган': 728, 'водител': 729, 'ситуац': 730, 'межд': 731, 'будеш': 732, 'заора': 733, 'унитаз': 734, 'взят': 735, 'пив': 736, 'специальн': 737, 'дум': 738, 'остальн': 739, 'придума': 740, 'траха': 741, 'шли': 742, 'тих': 743, 'счита': 744, 'ребенк': 745, 'зде': 746, 'завтр': 747, 'подар': 748, 'гол': 749, 'мудак': 750, 'лиш': 751, 'б': 752, 'чо': 753, 'небольш': 754, 'успел': 755, 'ахуен': 756, 'крича': 757, 'слома': 758, 'дырк': 759, 'цвет': 760, 'знатн': 761, 'тян': 762, 'комп': 763, 'рыб': 764, 'ссат': 765, 'набуха': 766, 'пельмен': 767, 'бо': 768, 'познаком': 769, 'убира': 770, 'слез': 771, 'мусор': 772, 'шел': 773, 'вон': 774, 'похож': 775, 'схват': 776, 'сзад': 777, 'увид': 778, 'прода': 779, 'подхож': 780, 'стор': 781, 'далек': 782, 'повод': 783, 'прочита': 784, 'ушел': 785, 'открыт': 786, 'одноклассниц': 787, 'жар': 788, 'мяс': 789, 'шок': 790, 'учительниц': 791, 'половин': 792, 'выясн': 793, 'вечн': 794, 'идет': 795, 'правд': 796, 'поздн': 797, 'книг': 798, 'шл': 799, 'скаж': 800, 'дошл': 801, 'соседн': 802, 'песн': 803, 'бог': 804, 'центр': 805, 'район': 806, 'идм': 807, 'поднима': 808, 'куртк': 809, 'прыга': 810, 'видн': 811, 'вк': 812, 'разговор': 813, 'губ': 814, 'соглас': 815, 'черн': 816, 'пом': 817, 'вниман': 818, 'прихож': 819, 'фильм': 820, 'стул': 821, 'бесплатн': 822, 'подроч': 823, 'провер': 824, 'язык': 825, 'беремен': 826, 'прекрасн': 827, 'пиздюл': 828, 'собствен': 829, 'застав': 830, 'добр': 831, 'закрыва': 832, 'хуев': 833, 'ржал': 834, 'помоч': 835, 'род': 836, 'здоров': 837, 'бомжих': 838, 'кошк': 839, 'сиськ': 840, 'куст': 841, 'хочеш': 842, 'палат': 843, 'фраз': 844, 'лев': 845, 'чел': 846, 'настольк': 847, 'родственник': 848, 'залетел': 849, 'фот': 850, 'рост': 851, 'счаст': 852, 'труб': 853, 'слыша': 854, 'трубк': 855, 'умер': 856, 'стат': 857, 'вход': 858, 'правильн': 859, 'вперед': 860, 'какиет': 861, 'сюд': 862, 'сом': 863, 'угол': 864, 'х': 865, 'родн': 866, 'меньш': 867, 'погуля': 868, 'особ': 869, 'парт': 870, 'соса': 871, 'берет': 872, 'виде': 873, 'шкаф': 874, 'коляск': 875, 'кабинк': 876, 'те': 877, 'угл': 878, 'цен': 879, 'кра': 880, 'поход': 881, 'пишет': 882, 'крова': 883, 'бер': 884, 'таков': 885, 'корм': 886, 'встав': 887, 'сон': 888, 'тоб': 889, 'лагер': 890, 'какуют': 891, 'экзам': 892, 'парк': 893, 'попыта': 894, 'школьн': 895, 'испуга': 896, 'возможн': 897, 'прикол': 898, 'нибуд': 899, 'вокруг': 900, 'москв': 901, 'включа': 902, 'настоя': 903, 'помог': 904, 'найт': 905, 'взросл': 906, 'ебл': 907, 'вниз': 908, 'кореш': 909, 'путин': 910, 'яблок': 911, 'выбор': 912, 'огород': 913, 'нех': 914, 'неч': 915, 'толка': 916, 'закрыт': 917, 'одежд': 918, 'поведа': 919, 'фотк': 920, 'реальн': 921, 'пачк': 922, 'доч': 923, 'товарищ': 924, 'мор': 925, 'лег': 926, 'тачк': 927, 'живет': 928, 'ебал': 929, 'дар': 930, 'садик': 931, 'конча': 932, 'гор': 933, 'мама': 934, 'целова': 935, 'принос': 936, 'пил': 937, 'держа': 938, 'выл': 939, 'оттуд': 940, 'сдава': 941, 'смех': 942, 'сердц': 943, 'мыт': 944, 'женск': 945, 'ком': 946, 'проч': 947, 'двум': 948, 'бесконечн': 949, 'отпуст': 950, 'шаг': 951, 'нож': 952, 'шкур': 953, 'став': 954, 'народ': 955, 'такс': 956, 'лавочк': 957, 'сок': 958, 'появ': 959, 'жирух': 960, 'шашлык': 961, 'побед': 962, 'зайт': 963, 'толчк': 964, 'наста': 965, 'км': 966, 'холодн': 967, 'расскаж': 968, 'красн': 969, 'извин': 970, 'джинс': 971, 'выбежа': 972, 'грязн': 973, 'будут': 974, 'родак': 975, 'использова': 976, 'посмотр': 977, 'шо': 978, 'камер': 979, 'минет': 980, 'полност': 981, 'посад': 982, 'гандон': 983, 'препод': 984, 'любл': 985, 'поц': 986, 'стремн': 987, 'переста': 988, 'подарк': 989, 'выйт': 990, 'прошел': 991, 'лют': 992, 'кем': 993, 'продолж': 994, 'звонок': 995, 'дерев': 996, 'мелоч': 997, 'одел': 998, 'проблем': 999}\n"
     ]
    }
   ],
   "source": [
    "word_2_ind = {vocabulary[i]:i for i in range(VOC_SIZE)}\n",
    "print(word_2_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_vector(story, show_unknown=False):\n",
    "    vector=np.zeros(VOC_SIZE, dtype=np.int_)\n",
    "    for word in tokenizer.tokenize(story):\n",
    "        stem=get_stem(word)\n",
    "        idx=word_2_ind.get(stem,None)\n",
    "        if idx is not None:\n",
    "            vector[idx]=1\n",
    "        elif show_unknown:\n",
    "            print('Unknown stem '+word)\n",
    "    return vector  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Ytmp = d.values()\n",
    "Y=[]\n",
    "\n",
    "for i in Ytmp:\n",
    "    Y.append(int(i>0.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stories to vectors via bag of words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\n",
      "1628\n",
      "1999\n",
      "1999\n"
     ]
    }
   ],
   "source": [
    "#proprocess storyes. Separate good ones from bad ones\n",
    "goods=[]\n",
    "bads=[]\n",
    "for pair in d.items():\n",
    "    if pair[1]>=0.05:\n",
    "        goods.append(pair[0])\n",
    "    else:\n",
    "        bads.append(pair[0])\n",
    "print(len(goods))\n",
    "print(len(bads))           \n",
    "vectors = np.zeros((len(d.items()), VOC_SIZE), dtype=np.int_)\n",
    "stories=[]\n",
    "for i in goods:\n",
    "    stories.append(to_vector(i))\n",
    "for i in bads:\n",
    "    stories.append(to_vector(i))\n",
    "X=[]\n",
    "for i in stories:\n",
    "    X.append(i) \n",
    "print(len(X))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=np.append(np.zeros(len(bads), dtype=np.int_), np.ones(len(goods), dtype=np.int_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5997"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=open('X.txt', 'wt')\n",
    "f.write(str(X))\n",
    "f=open('Y.txt', 'wt')\n",
    "f.write(str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from math import exp\n",
    "\n",
    "class NN:\n",
    "\n",
    "    def __init__(self, n_input=None, n_output=None, n_hidden_nodes=None):\n",
    "        self.n_input = n_input  \n",
    "        self.n_output = n_output  \n",
    "        self.n_hidden_nodes = n_hidden_nodes  \n",
    "        self.network = self._build_network()\n",
    "\n",
    "    def train(self, X_train, y_train, l_rate=None, n_epochs=None):\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            for (x, y) in zip(X_train, y_train):\n",
    "                \n",
    "                self._forward_pass(x)\n",
    "                \n",
    "                y_target = np.zeros(self.n_output, dtype=np.int)\n",
    "                y_target[y] = 1\n",
    "              \n",
    "                self._backward_pass(y_target)\n",
    "                \n",
    "               \n",
    "                self._update_weights(x, l_rate=l_rate)\n",
    "\n",
    "   \n",
    "    def predict(self, X):\n",
    "\n",
    "        y_predict = np.zeros(len(X), dtype=np.int)\n",
    "        for i, x in enumerate(X):\n",
    "            output = self._forward_pass(x)  \n",
    "            y_predict[i] = np.argmax(output)  \n",
    "\n",
    "        return y_predict\n",
    "\n",
    "\n",
    "    def _build_network(self):\n",
    "\n",
    "        \n",
    "        def _build_layer(n_input, n_output):\n",
    "            layer = list()\n",
    "            for idx_out in range(n_output):\n",
    "                weights = list()\n",
    "                for idx_in in range(n_input):\n",
    "                    weights.append(random.random())\n",
    "                layer.append({\"weights\": weights,\n",
    "                              \"output\": None,\n",
    "                              \"delta\": None})\n",
    "            return layer\n",
    "\n",
    "        \n",
    "        n_hidden_layers = len(self.n_hidden_nodes)\n",
    "        network = list()\n",
    "        if n_hidden_layers == 0:\n",
    "            network.append(_build_layer(self.n_input, self.n_output))\n",
    "        else:\n",
    "            network.append(_build_layer(self.n_input, self.n_hidden_nodes[0]))\n",
    "            for i in range(1,n_hidden_layers):\n",
    "                network.append(_build_layer(self.n_hidden_nodes[i-1],\n",
    "                                            self.n_hidden_nodes[i]))\n",
    "            network.append(_build_layer(self.n_hidden_nodes[n_hidden_layers-1],\n",
    "                                        self.n_output))\n",
    "\n",
    "        return network\n",
    "\n",
    "\n",
    "    def _forward_pass(self, x):\n",
    "\n",
    "        \n",
    "        def activate(weights, inputs):\n",
    "            activation = 0.0\n",
    "            for i in range(len(weights)):\n",
    "                activation += weights[i] * inputs[i]\n",
    "            return activation\n",
    "\n",
    "  \n",
    "        input = x\n",
    "        for layer in self.network:\n",
    "            output = list()\n",
    "            for node in layer:\n",
    "                # Compute activation and apply transfer to it\n",
    "                activation = activate(node['weights'], input)\n",
    "                node['output'] = self._transfer(activation)\n",
    "                output.append(node['output'])\n",
    "            input = output\n",
    "\n",
    "        return input\n",
    "\n",
    "    \n",
    "    def _backward_pass(self, target):\n",
    "\n",
    "        \n",
    "        n_layers = len(self.network)\n",
    "        for i in reversed(range(n_layers)):\n",
    "            layer = self.network[i]\n",
    "\n",
    "            \n",
    "            errors = list()\n",
    "            if i == n_layers - 1:\n",
    "                \n",
    "                for j, node in enumerate(layer):\n",
    "                    error = target[j] - node['output']\n",
    "                    errors.append(error)\n",
    "            else:\n",
    "                \n",
    "                for j, node in enumerate(layer):\n",
    "                    error = 0.0\n",
    "                    for node in self.network[i + 1]:\n",
    "                        error += node['weights'][j] * node['delta']\n",
    "                    errors.append(error)\n",
    "\n",
    "            \n",
    "            for j, node in enumerate(layer):\n",
    "                node['delta'] = errors[j] * self._transfer_derivative(node['output'])\n",
    "\n",
    "  \n",
    "    def _update_weights(self, x, l_rate=0.3):\n",
    "\n",
    "        \n",
    "        for i_layer, layer in enumerate(self.network):\n",
    "\n",
    "            \n",
    "            if i_layer == 0:\n",
    "                inputs = x\n",
    "            else:\n",
    "                inputs = np.zeros(len(self.network[i_layer - 1]))\n",
    "                for i_node, node in enumerate(self.network[i_layer - 1]):\n",
    "                    inputs[i_node] = node['output']\n",
    "\n",
    "            \n",
    "            for node in layer:\n",
    "                for j, input in enumerate(inputs):\n",
    "                    dW = l_rate * node['delta'] * input\n",
    "                    node['weights'][j] += dW\n",
    "\n",
    "  \n",
    "    def _transfer(self, x):\n",
    "        return 1.0/(1.0+exp(-x))\n",
    "\n",
    "    \n",
    "    def _transfer_derivative(self, transfer):\n",
    "        return transfer*(1.0-transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(n_input=VOC_SIZE, n_output=2, n_hidden_nodes=[5])\n",
    "model.train(X_train, Y_train, l_rate=0.65, n_epochs=1000)\n",
    "y_test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.658888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1\n",
      " 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1\n",
      " 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 1 1 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
